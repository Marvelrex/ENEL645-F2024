{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step MNIST Digits Classification - Simple Fully Connected Neural Network for MNIST Classification - PyTorch\n",
    "\n",
    "In this example, we will see how to implement a simple fully connected neural network using PyTorch for classifying the digits in the MNIST dataset.\n",
    "\n",
    "1. Set your data loader, explore your data \n",
    "\n",
    "2. Define your model\n",
    "\n",
    "3. Train your model with the appropriate loss function, optmizer, learning rate, batch_size, checkpoints, etc.\n",
    "\n",
    "    3.1 If you are satisfied with the train and validation performance go to the next step\n",
    "\n",
    "    3.2 If you are not satisfied with the train and validation performance go back to step 5\n",
    "\n",
    "4. Test your model on the test and extract relevant metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch # pytorch main library \n",
    "import torchvision # computer vision utilities\n",
    "import torchvision.transforms as transforms # transforms used in the pre-processing of the data\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get thge statistics of a dataset\n",
    "def get_dataset_stats(data_loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in data_loader:\n",
    "        data = data[0] # Get the images to compute the stgatistics\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "        \n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean,std\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img,stats):\n",
    "    img = img *stats[1] + stats[0]     # unnormalize\n",
    "    npimg = img.numpy() # convert the tensor back to numpy\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stats: (tensor([0.1307]), tensor([0.3016]))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]) # Convert the data to a PyTorch tensor\n",
    "\n",
    "# Load develpoment dataset\n",
    "devset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform = transform)\n",
    "\n",
    "train_set_size = int(len(devset) * 0.8)\n",
    "val_set_size = len(devset) - train_set_size\n",
    "\n",
    "# Split the development set into train and validation\n",
    "trainset, valset = torch.utils.data.random_split(devset, [train_set_size, val_set_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "\n",
    "# Get the data loader for the train set\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Comopute the statistics of the train set\n",
    "stats = get_dataset_stats(trainloader)\n",
    "print(\"Train stats:\", stats)\n",
    "# Pre-processing transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((stats[0]), (stats[1]))])\n",
    "\n",
    "\n",
    "# Load the development set again using the proper pre-processing transforms\n",
    "devset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform = transform)\n",
    "\n",
    "# Split the development set into train and validation\n",
    "trainset, valset = torch.utils.data.random_split(devset, [train_set_size, val_set_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Get the data loader for the train set\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Get the data loader for the test set\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Get the test set\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# Get the data loader for the test set\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('zero', 'one', 'two', 'three',\n",
    "           'four', 'five', 'six', 'seven', 'eight', 'nine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nine  one   three seven seven five  three two  \n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:8]), stats)\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input channel (grayscale), 32 output channels, 3x3 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128) # Adjust size according to the image size after convolutions\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layer + ReLU + MaxPooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # Flatten the tensor into a 1D vector\n",
    "        x = x.view(-1, 64 * 12 * 12)\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No softmax needed as we'll apply CrossEntropyLoss\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # Optimizer used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,  train loss: 0.994, val loss: 0.383\n",
      "Saving model\n",
      "2,  train loss: 0.323, val loss: 0.313\n",
      "Saving model\n",
      "3,  train loss: 0.268, val loss: 0.269\n",
      "Saving model\n",
      "4,  train loss: 0.228, val loss: 0.227\n",
      "Saving model\n",
      "5,  train loss: 0.195, val loss: 0.199\n",
      "Saving model\n",
      "6,  train loss: 0.169, val loss: 0.181\n",
      "Saving model\n",
      "7,  train loss: 0.150, val loss: 0.162\n",
      "Saving model\n",
      "8,  train loss: 0.134, val loss: 0.142\n",
      "Saving model\n",
      "9,  train loss: 0.119, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# since we're not training, we don't need to calculate the gradients for our outputs\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(valloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;66;03m# get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     31\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n",
      "File \u001b[1;32mc:\\Users\\rober\\anaconda3\\envs\\pytorch-monai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\rober\\anaconda3\\envs\\pytorch-monai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1319\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[1;32m-> 1319\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \n\u001b[0;32m   1324\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rober\\anaconda3\\envs\\pytorch-monai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1445\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[0;32m   1444\u001b[0m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[1;32m-> 1445\u001b[0m     \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues:\n\u001b[0;32m   1447\u001b[0m     q\u001b[38;5;241m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[1;32mc:\\Users\\rober\\anaconda3\\envs\\pytorch-monai\\lib\\multiprocessing\\process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rober\\anaconda3\\envs\\pytorch-monai\\lib\\multiprocessing\\popen_spawn_win32.py:108\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     msecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m--> 108\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsecs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWAIT_OBJECT_0:\n\u001b[0;32m    110\u001b[0m     code \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mGetExitCodeProcess(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nepochs = 20\n",
    "PATH = './cifar_net.pth' # Path to save the best model\n",
    "\n",
    "best_loss = 1e+20\n",
    "for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "    # Training Loop\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print(f'{epoch + 1},  train loss: {train_loss / i:.3f},', end = ' ')\n",
    "    \n",
    "    val_loss = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "        print(f'val loss: {val_loss / i:.3f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_loss:\n",
    "            print(\"Saving model\")\n",
    "            torch.save(net.state_dict(), PATH)\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model to be used in the test set\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[:4]), stats)\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "249d11310564531dbb0422c65726fbafe5d71a3f15733fe196d56460bed7c227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
